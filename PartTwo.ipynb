{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ad6c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jimena/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531f9ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7815\n",
      "Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "def clean_hansard(filepath):\n",
    "    \"\"\"Returns a clean dataframe from the hansard dataset\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['party'] = df['party'].replace({'Labour (Co-op)': 'Labour'})\n",
    "    # print(df['party'].unique())\n",
    "\n",
    "    party_counts = df['party'].value_counts()\n",
    "    main_parties = party_counts.nlargest(4).index.tolist()\n",
    "    df = df[df['party'].isin(main_parties)]\n",
    "    # print(df['party'].value_counts())\n",
    "\n",
    "    # 4th party 'Speaker'. Remove it.\n",
    "    df = df[df['party'] != 'Speaker']\n",
    "    # print(df['party'].value_counts())\n",
    "\n",
    "    df = df[df[\"speech_class\"] == \"Speech\"]\n",
    "    speech_lengths = df[\"speech\"].str.len()\n",
    "    speeches = speech_lengths >= 1000\n",
    "    df = df[speeches]\n",
    "\n",
    "    rows, columns = df.shape\n",
    "    print(f\"Number of rows: {rows}\")\n",
    "    print(f\"Number of columns: {columns}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = clean_hansard(\"p2-texts/hansard40000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33040f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer that removes common English words and limits the number of features to the 3000 most frequent terms.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "\n",
    "# Vectorise the speeches\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df[\"party\"]\n",
    "\n",
    "# Stratified by labels to ensure class proportions whithin parties, with a random seed of 26.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "# print(features_train.shape, features_test.shape)\n",
    "# print(labels_train.value_counts(normalize=True))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0f82d",
   "metadata": {},
   "source": [
    "The dataset is imbalanced (Conservative: 0.616603, Labour: 0.296545, Scottish National Party: 0.086852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f63a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.6269718149483269\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.74      0.98      0.84       964\n",
      "                 Labour       0.79      0.43      0.56       463\n",
      "Scottish National Party       0.96      0.32      0.48       136\n",
      "\n",
      "               accuracy                           0.76      1563\n",
      "              macro avg       0.83      0.58      0.63      1563\n",
      "           weighted avg       0.78      0.76      0.73      1563\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.7871964473639963\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.85      0.92      0.89       964\n",
      "                 Labour       0.79      0.71      0.75       463\n",
      "Scottish National Party       0.83      0.65      0.73       136\n",
      "\n",
      "               accuracy                           0.83      1563\n",
      "              macro avg       0.83      0.76      0.79      1563\n",
      "           weighted avg       0.83      0.83      0.83      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def random_forest_and_linearsvm_performance(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"Trains RandomForest and SVM classifiers and prints macro-average f1 score and classification reports\"\"\"\n",
    "\n",
    "    # 300 trees in the Random Forest, with a random seed of 26.\n",
    "    random_forest = RandomForestClassifier(n_estimators=300, random_state=26)\n",
    "    random_forest.fit(features_train, labels_train)\n",
    "    rf_predict = random_forest.predict(features_test)\n",
    "\n",
    "    random_forest_f1 = f1_score(labels_test, rf_predict, average=\"macro\")\n",
    "    random_forest_report = classification_report(labels_test, rf_predict)\n",
    "\n",
    "    svm = SVC(kernel=\"linear\", random_state=26)\n",
    "    svm.fit(features_train, labels_train)\n",
    "    svm_predict = svm.predict(features_test)\n",
    "\n",
    "    svm_f1 = f1_score(labels_test, svm_predict, average=\"macro\")\n",
    "    svm_report = classification_report(labels_test, svm_predict)\n",
    "\n",
    "    print(f\"Random Forest classifier\\nf1 score: {random_forest_f1}\\nClassification report:\\n{random_forest_report}\")\n",
    "    print(f\"SVM linear classifier\\nf1 score: {svm_f1}\\nClassification report:\\n{svm_report}\")\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0082716d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.6748975043716996\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.76      0.97      0.85       964\n",
      "                 Labour       0.80      0.49      0.61       463\n",
      "Scottish National Party       0.95      0.40      0.57       136\n",
      "\n",
      "               accuracy                           0.78      1563\n",
      "              macro avg       0.84      0.62      0.67      1563\n",
      "           weighted avg       0.79      0.78      0.75      1563\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.7955796360349998\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.86      0.92      0.89       964\n",
      "                 Labour       0.79      0.73      0.76       463\n",
      "Scottish National Party       0.84      0.65      0.74       136\n",
      "\n",
      "               accuracy                           0.84      1563\n",
      "              macro avg       0.83      0.77      0.80      1563\n",
      "           weighted avg       0.84      0.84      0.84      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Prints the classification report adjusting the parameters of the Tfidfvectorizer so that unigrams, bi-grams and\n",
    "tri-grams are considered as features.\"\"\"\n",
    "\n",
    "# Modified vectorizer to include unigrams (1 word), bigrams (2 word) and trigrams (3 word) sequences.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000, ngram_range=(1,3))\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df['party']\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6e74b",
   "metadata": {},
   "source": [
    "Adding bigrams and trigrams improved performance as F1 and accuracy slightly increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188a7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Implement a new custom tokenizer and pass it to the tokenizer argument of Tfidfvectorizer. \n",
    "Try to achieve the best classification performance with same number of features (3000) and the same three classifiers. \n",
    "Print the classification report for the best performing classifier using your tokenizer.\"\"\"\n",
    "\n",
    "def custom_tokenizer_nltk(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # Keep only alphabetical words (remove numbers and punctuation).\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            clean_tokens.append(token.lower())\n",
    "    return clean_tokens\n",
    "        \n",
    "# text = \"Hello, world! This is a test\"\n",
    "# print(custom_tokenizer_nltk(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a23e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimena/.pyenv/versions/3.12.3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.6890668398952485\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.76      0.96      0.85       964\n",
      "                 Labour       0.80      0.47      0.60       463\n",
      "Scottish National Party       0.91      0.47      0.62       136\n",
      "\n",
      "               accuracy                           0.78      1563\n",
      "              macro avg       0.83      0.64      0.69      1563\n",
      "           weighted avg       0.79      0.78      0.76      1563\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.7909362022889694\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.86      0.92      0.89       964\n",
      "                 Labour       0.78      0.72      0.75       463\n",
      "Scottish National Party       0.84      0.65      0.74       136\n",
      "\n",
      "               accuracy                           0.84      1563\n",
      "              macro avg       0.83      0.76      0.79      1563\n",
      "           weighted avg       0.83      0.84      0.83      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer_nltk, stop_words='english', max_features=3000,\n",
    "    ngram_range=(1, 3))\n",
    "\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df['party']\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537bb36",
   "metadata": {},
   "source": [
    "The NLTK custom_tokenizer shows slighlty improvement in the Random Forest classifier but not in SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45515b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimena/.pyenv/versions/3.12.3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.6772205613967802\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.76      0.96      0.85       964\n",
      "                 Labour       0.79      0.48      0.60       463\n",
      "Scottish National Party       0.91      0.43      0.59       136\n",
      "\n",
      "               accuracy                           0.77      1563\n",
      "              macro avg       0.82      0.62      0.68      1563\n",
      "           weighted avg       0.78      0.77      0.75      1563\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.7881888199127838\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.85      0.92      0.88       964\n",
      "                 Labour       0.78      0.72      0.75       463\n",
      "Scottish National Party       0.85      0.65      0.73       136\n",
      "\n",
      "               accuracy                           0.83      1563\n",
      "              macro avg       0.83      0.76      0.79      1563\n",
      "           weighted avg       0.83      0.83      0.83      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try with up to bigrams (2 word) sequence.\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer_nltk, stop_words='english', max_features=3000,\n",
    "    ngram_range=(1, 2))\n",
    "\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df['party']\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6095045",
   "metadata": {},
   "source": [
    "For the custom tokenizer will try first to clean the text as in the parsing unwanted characters like  \\n, \\n\\n, ', ., -- were observed (may try with NLTK and then with spaCy).\n",
    "Will try also with up to 2 ngrams.\n",
    "Will try removing rare tokens.\n",
    "Will try removing very frequent words that may be used by every party and may not be distinctive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
