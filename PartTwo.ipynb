{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11ad6c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jimena/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jimena/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/jimena/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "531f9ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8084\n",
      "Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset and print its shape\n",
    "    \n",
    "df = pd.read_csv(\"p2-texts/hansard40000.csv\")\n",
    "df['party'] = df['party'].replace({'Labour (Co-op)': 'Labour'})\n",
    "# print(df['party'].unique())\n",
    "\n",
    "# Remove 'Speaker'\n",
    "df = df[df['party'] != 'Speaker']\n",
    "# print(df['party'].value_counts())\n",
    "\n",
    "party_counts = df['party'].value_counts()\n",
    "main_parties = party_counts.nlargest(4).index.tolist()\n",
    "df = df[df['party'].isin(main_parties)]\n",
    "# print(df['party'].value_counts())\n",
    "\n",
    "df = df[df[\"speech_class\"] == \"Speech\"]\n",
    "speech_lengths = df[\"speech\"].str.len()\n",
    "speeches = speech_lengths >= 1000\n",
    "df = df[speeches]\n",
    "\n",
    "rows, columns = df.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a33040f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer that removes common English words and limits the number of features to the 3000 most frequent terms.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "\n",
    "# Vectorise the speeches\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df[\"party\"]\n",
    "\n",
    "# Stratified by labels to ensure class proportions whithin parties, with a random seed of 26.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "# print(features_train.shape, features_test.shape)\n",
    "# print(labels_train.value_counts(normalize=True))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0f82d",
   "metadata": {},
   "source": [
    "The dataset is imbalanced (Conservative: 0.596103, Labour: 0.286686, Scottish National Party: 0.083965, Liberal Democrat 0.033246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f63a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.45422557608349956\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.72      0.98      0.83       964\n",
      "                 Labour       0.75      0.44      0.55       463\n",
      "       Liberal Democrat       0.00      0.00      0.00        54\n",
      "Scottish National Party       0.89      0.29      0.43       136\n",
      "\n",
      "               accuracy                           0.73      1617\n",
      "              macro avg       0.59      0.43      0.45      1617\n",
      "           weighted avg       0.72      0.73      0.69      1617\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.5933446121140653\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.83      0.92      0.87       964\n",
      "                 Labour       0.74      0.71      0.72       463\n",
      "       Liberal Democrat       1.00      0.07      0.14        54\n",
      "Scottish National Party       0.78      0.54      0.64       136\n",
      "\n",
      "               accuracy                           0.80      1617\n",
      "              macro avg       0.84      0.56      0.59      1617\n",
      "           weighted avg       0.81      0.80      0.79      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def random_forest_and_linearsvm_performance(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"Trains RandomForest and SVM classifiers and prints macro-average f1 score and classification reports\"\"\"\n",
    "\n",
    "    # 300 trees in the Random Forest, with a random seed of 26.\n",
    "    random_forest = RandomForestClassifier(n_estimators=300, random_state=26)\n",
    "    random_forest.fit(features_train, labels_train)\n",
    "    rf_predict = random_forest.predict(features_test)\n",
    "\n",
    "    # Added zero_division to handle 0.0 precision warning \n",
    "    random_forest_f1 = f1_score(labels_test, rf_predict, average=\"macro\")\n",
    "    random_forest_report = classification_report(labels_test, rf_predict, zero_division=0)\n",
    "\n",
    "    svm = SVC(kernel=\"linear\", random_state=26)\n",
    "    svm.fit(features_train, labels_train)\n",
    "    svm_predict = svm.predict(features_test)\n",
    "\n",
    "    svm_f1 = f1_score(labels_test, svm_predict, average=\"macro\")\n",
    "    svm_report = classification_report(labels_test, svm_predict)\n",
    "\n",
    "    print(f\"Random Forest classifier\\nf1 score: {random_forest_f1}\\nClassification report:\\n{random_forest_report}\")\n",
    "    print(f\"SVM linear classifier\\nf1 score: {svm_f1}\\nClassification report:\\n{svm_report}\")\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b6256",
   "metadata": {},
   "source": [
    "Liberal Democrat is not being predicted with the Random Forest classifier. Getting a warning message solved with zero_division.\n",
    "\n",
    "Random Forest classifier\n",
    "f1 score: 0.45422557608349956\n",
    "SVM linear classifier\n",
    "f1 score: 0.5933446121140653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0082716d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.47930475175651455\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.74      0.96      0.83       964\n",
      "                 Labour       0.75      0.48      0.58       463\n",
      "       Liberal Democrat       0.00      0.00      0.00        54\n",
      "Scottish National Party       0.84      0.35      0.50       136\n",
      "\n",
      "               accuracy                           0.74      1617\n",
      "              macro avg       0.58      0.45      0.48      1617\n",
      "           weighted avg       0.72      0.74      0.71      1617\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.5854220473255666\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.84      0.92      0.88       964\n",
      "                 Labour       0.75      0.73      0.74       463\n",
      "       Liberal Democrat       1.00      0.04      0.07        54\n",
      "Scottish National Party       0.78      0.56      0.65       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.84      0.56      0.59      1617\n",
      "           weighted avg       0.81      0.81      0.79      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Prints the classification report adjusting the parameters of the Tfidfvectorizer so that unigrams, bi-grams and\n",
    "tri-grams are considered as features.\"\"\"\n",
    "\n",
    "# Modified vectorizer to include unigrams (1 word), bigrams (2 word) and trigrams (3 word) sequences.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000, ngram_range=(1,3))\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df['party']\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6e74b",
   "metadata": {},
   "source": [
    "Random Forest classifier\n",
    "f1 score: 0.47930475175651455\n",
    "SVM linear classifier\n",
    "f1 score: 0.5854220473255666\n",
    "Adding bigrams and trigrams improved F1 score for RF, not accuracy. Wrost F1 score for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "188a7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Implement a new custom tokenizer and pass it to the tokenizer argument of Tfidfvectorizer. \n",
    "Try to achieve the best classification performance with same number of features (3000) and the same three classifiers. \n",
    "Print the classification report for the best performing classifier using your tokenizer.\"\"\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def custom_tokenizer_nltk(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "       token = token.lower()\n",
    "       if token.isalpha() and token not in stop_words:\n",
    "        lemma = lemmatizer.lemmatize(token)\n",
    "        if len(token) > 1:\n",
    "           clean_tokens.append(lemma)\n",
    "    return clean_tokens\n",
    "        \n",
    "# text = \"Hello, world! This is a test\"\n",
    "# print(custom_tokenizer_nltk(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1872341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63     [less, two, week, since, government, launched,...\n",
      "99     [delighted, announce, last, friday, reached, a...\n",
      "100    [thank, secretary, state, advance, sight, stat...\n",
      "101    [right, hon, lady, congratulation, securing, i...\n",
      "104    [congratulate, secretary, state, recognise, al...\n",
      "Name: speech, dtype: object\n"
     ]
    }
   ],
   "source": [
    "texts = df['speech']\n",
    "\n",
    "tokenized_texts = texts.apply(custom_tokenizer_nltk)\n",
    "\n",
    "# print(tokenized_texts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adc184bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimena/.pyenv/versions/3.12.3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.5051579755563204\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.73      0.96      0.83       964\n",
      "                 Labour       0.75      0.48      0.58       463\n",
      "       Liberal Democrat       1.00      0.06      0.11        54\n",
      "Scottish National Party       0.90      0.35      0.50       136\n",
      "\n",
      "               accuracy                           0.74      1617\n",
      "              macro avg       0.85      0.46      0.51      1617\n",
      "           weighted avg       0.76      0.74      0.71      1617\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.6252689802421786\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.83      0.93      0.87       964\n",
      "                 Labour       0.74      0.70      0.72       463\n",
      "       Liberal Democrat       0.89      0.15      0.25        54\n",
      "Scottish National Party       0.80      0.55      0.65       136\n",
      "\n",
      "               accuracy                           0.80      1617\n",
      "              macro avg       0.81      0.58      0.63      1617\n",
      "           weighted avg       0.80      0.80      0.79      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=custom_tokenizer_nltk, \n",
    "    preprocessor=None, lowercase=False, stop_words=None, \n",
    "    max_features=3000, ngram_range=(1, 3)\n",
    "    )\n",
    "\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df[\"party\"]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b9cbc",
   "metadata": {},
   "source": [
    "unigrams\n",
    "Random Forest classifier\n",
    "f1 score: 0.43523748230145454\n",
    "SVM linear classifier\n",
    "f1 score: 0.5899504098866261\n",
    "bigrams\n",
    "Random Forest classifier\n",
    "f1 score: 0.4960422798007194\n",
    "SVM linear classifier\n",
    "f1 score: 0.6227610514154456\n",
    "trigrams\n",
    "Random Forest classifier\n",
    "f1 score: 0.5051579755563204 \n",
    "# down to 0.4900020900816393 if vectorizer token len >2 insted of >1 \n",
    "# down to 0.4762973139164108 if not applying lemmatization to tokenizer \n",
    "SVM linear classifier\n",
    "f1 score: 0.6252689802421786\n",
    "# down to 0.6095657098971895 if tokenizer len >2 insted of >1\n",
    "# down to 0.5829744192780167 if not applying lemmatization to tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17e10f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    clean_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.is_alpha and \n",
    "            not token.is_stop and     \n",
    "            len(token.lemma_) > 1): \n",
    "            clean_tokens.append(token.lemma_.lower())\n",
    "    return clean_tokens\n",
    "\n",
    "# text = \"Hello, world! This is a test\"\n",
    "# print(custom_tokenizer_spacy(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a8ea34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimena/.pyenv/versions/3.12.3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "f1 score: 0.3177120531855518\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.66      1.00      0.80       964\n",
      "                 Labour       0.82      0.28      0.42       463\n",
      "       Liberal Democrat       0.00      0.00      0.00        54\n",
      "Scottish National Party       1.00      0.03      0.06       136\n",
      "\n",
      "               accuracy                           0.68      1617\n",
      "              macro avg       0.62      0.33      0.32      1617\n",
      "           weighted avg       0.71      0.68      0.60      1617\n",
      "\n",
      "SVM linear classifier\n",
      "f1 score: 0.5628320204715067\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.82      0.94      0.88       964\n",
      "                 Labour       0.75      0.70      0.72       463\n",
      "       Liberal Democrat       1.00      0.02      0.04        54\n",
      "Scottish National Party       0.83      0.49      0.62       136\n",
      "\n",
      "               accuracy                           0.80      1617\n",
      "              macro avg       0.85      0.54      0.56      1617\n",
      "           weighted avg       0.81      0.80      0.78      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), preprocessor=None, lowercase=False)\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df['party']\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "random_forest_and_linearsvm_performance(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e59bd2",
   "metadata": {},
   "source": [
    "Lower performance and less efficient using spaCy.\n",
    "Random Forest classifier\n",
    "f1 score: 0.3177120531855518\n",
    "SVM linear classifier\n",
    "f1 score: 0.5628320204715067"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf8d04",
   "metadata": {},
   "source": [
    "After running diffrent values, the reducuction of very common words doesn't make any changes. But performance improves for the SVM classifier removing tokens present in fewer that 3 documments and decreces for the Random Forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6095045",
   "metadata": {},
   "source": [
    "For the custom tokenizer will try first to clean the text as in the parsing unwanted characters like  \\n, \\n\\n, ', ., -- were observed (may try with NLTK and then with spaCy).\n",
    "Will try also with up to 2 ngrams.\n",
    "Will try removing rare tokens.\n",
    "Will try removing very frequent words that may be used by every party and may not be distinctive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
