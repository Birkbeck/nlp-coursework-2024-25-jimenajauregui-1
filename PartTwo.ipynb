{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11ad6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "531f9ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7815\n",
      "Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "def clean_hansard(filepath):\n",
    "    \"\"\"Returns a clean dataframe from the hansard dataset\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['party'] = df['party'].replace({'Labour (Co-op)': 'Labour'})\n",
    "    # print(df['party'].unique())\n",
    "\n",
    "    party_counts = df['party'].value_counts()\n",
    "    main_parties = party_counts.nlargest(4).index.tolist()\n",
    "    df = df[df['party'].isin(main_parties)]\n",
    "    # print(df['party'].value_counts())\n",
    "\n",
    "    # 4th party 'Speaker'. Remove it.\n",
    "    df = df[df['party'] != 'Speaker']\n",
    "    # print(df['party'].value_counts())\n",
    "\n",
    "    df = df[df[\"speech_class\"] == \"Speech\"]\n",
    "    speech_lengths = df[\"speech\"].str.len()\n",
    "    speeches = speech_lengths >= 1000\n",
    "    df = df[speeches]\n",
    "\n",
    "    rows, columns = df.shape\n",
    "    print(f\"Number of rows: {rows}\")\n",
    "    print(f\"Number of columns: {columns}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = clean_hansard(\"p2-texts/hansard40000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33040f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer that removes common English words and limits the number of features to the 3000 most frequent terms.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "\n",
    "# Vectorise the speeches\n",
    "features = vectorizer.fit_transform(df['speech'])\n",
    "labels = df[\"party\"]\n",
    "\n",
    "# Stratified by labels to ensure class proportions whithin parties, with a random seed of 26.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.2, random_state= 26, stratify= labels)\n",
    "\n",
    "# print(features_train.shape, features_test.shape)\n",
    "# print(labels_train.value_counts(normalize=True))\n",
    "# The data set is imbalanced (Conservative: 0.616603, Labour: 0.296545, Scottish National Party: 0.086852)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
